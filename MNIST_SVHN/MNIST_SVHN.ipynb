{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "psychological-isaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from importance_sampler_poise.ipynb\n",
      "importing Jupyter notebook from data_preprocessing.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "import importance_sampler_poise\n",
    "import data_preprocessing\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F  #for the activation function\n",
    "from torchviz import make_dot\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import umap\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ultimate-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning parameters\n",
    "latent_dim1 = 2\n",
    "latent_dim2 = 2\n",
    "batch_size = 64\n",
    "dim_MNIST   = 784\n",
    "lr = 1e-4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tx = transforms.ToTensor()\n",
    "MNIST_TRAINING_PATH = \"/home/achint/Practice_code/VAE/MNIST/MNIST/processed/training.pt\"\n",
    "SVHN_TRAINING_PATH  = \"/home/achint/Practice_code/VAE/SVHN/train_32x32.mat\"\n",
    "MNIST_TEST_PATH     = \"/home/achint/Practice_code/VAE/MNIST/MNIST/processed/test.pt\"\n",
    "SVHN_TEST_PATH  = \"/home/achint/Practice_code/VAE/SVHN/test_32x32.mat\"\n",
    "SUMMARY_WRITER_PATH = \"/home/achint/Practice_code/logs\"\n",
    "RECONSTRUCTION_PATH = \"/home/achint/Practice_code/1_a_new_start/MNIST_SVHN/reconstructions/\"\n",
    "PATH = \"/home/achint/Practice_code/1_a_new_start/MNIST_SVHN/weights.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "portable-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the logs directory and the reconstruction directory \n",
    "if os.path.exists(RECONSTRUCTION_PATH):\n",
    "    shutil.rmtree(RECONSTRUCTION_PATH)\n",
    "    os.makedirs(RECONSTRUCTION_PATH)\n",
    "\n",
    "if os.path.exists(SUMMARY_WRITER_PATH):\n",
    "    shutil.rmtree(SUMMARY_WRITER_PATH)\n",
    "    os.makedirs(SUMMARY_WRITER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dress-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing MNIST and SVHN datasets\n",
    "joint_dataset_train=data_preprocessing.JointDataset(mnist_pt_path=MNIST_TRAINING_PATH,\n",
    "                             svhn_mat_path=SVHN_TRAINING_PATH)\n",
    "joint_dataset_test = data_preprocessing.JointDataset(mnist_pt_path=MNIST_TEST_PATH,\n",
    "                             svhn_mat_path=SVHN_TEST_PATH)\n",
    "\n",
    "joint_dataset_train_loader = DataLoader(\n",
    "    joint_dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "joint_dataset_test_loader = DataLoader(\n",
    "    joint_dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "statistical-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,latent_dim1, latent_dim2, batch_size,use_mse_loss=True):\n",
    "        super(VAE,self).__init__()\n",
    "        self.latent_dim1 = latent_dim1\n",
    "        self.latent_dim2 = latent_dim2\n",
    "        self.batch_size = batch_size\n",
    "        self.use_mse_loss = use_mse_loss\n",
    "        self.n_IW_samples = 20\n",
    "        self.IS_sampler              = importance_sampler_poise.importance_sampler(self.latent_dim1, self.latent_dim2, self.batch_size)\n",
    "        ## Encoder set1(MNIST)\n",
    "        self.set1_enc1 = nn.Linear(in_features = dim_MNIST,out_features = 512)\n",
    "        self.set1_enc2 = nn.Linear(in_features = 512,out_features = 128)\n",
    "        self.set1_enc3 = nn.Linear(in_features = 128,out_features = 2*latent_dim1)\n",
    "        \n",
    "        ## Decoder set1(MNIST)\n",
    "        self.set1_dec1 = nn.Linear(in_features = latent_dim1,out_features = 128)\n",
    "        self.set1_dec2 = nn.Linear(in_features = 128,out_features = 512)\n",
    "        self.set1_dec3 = nn.Linear(in_features = 512,out_features = dim_MNIST)\n",
    "        \n",
    "        ## Encoder set2(SVHN)\n",
    "        # input size: 3 x 32 x 32\n",
    "        self.set2_enc1 = nn.Conv2d(in_channels=3, out_channels=2*latent_dim2, kernel_size=4, stride=2, padding=1)\n",
    "        # size: 32 x 16 x 16\n",
    "        self.set2_enc2 = nn.Conv2d(in_channels=2*latent_dim2, out_channels=2*latent_dim2, kernel_size=4, stride=2, padding=1)\n",
    "        # size: 32 x 8 x 8\n",
    "        self.set2_enc3 = nn.Conv2d(in_channels=2*latent_dim2, out_channels=latent_dim2, kernel_size=4, stride=2, padding=1)\n",
    "        # size: 16 x 4 x 4    \n",
    "\n",
    "        ## Decoder set2(SVHN)\n",
    "        # input size: 16x1x1\n",
    "        self.set2_dec0 = nn.ConvTranspose2d(in_channels=latent_dim2,out_channels=latent_dim2, kernel_size=4, stride=1, padding=0)\n",
    "        # input size: 16x4x4\n",
    "        self.set2_dec1 = nn.ConvTranspose2d(in_channels=latent_dim2,out_channels=2*latent_dim2, kernel_size=3, stride=1, padding=1)\n",
    "        # size: 32 x 4 x 4\n",
    "        self.set2_dec2 = nn.ConvTranspose2d(in_channels=2*latent_dim2,out_channels=2*latent_dim2, kernel_size=5, stride=1, padding=0)\n",
    "        # size: 32 x 8 x 8\n",
    "        self.set2_dec3 = nn.ConvTranspose2d(in_channels=2*latent_dim2,out_channels=2*latent_dim2, kernel_size=4, stride=2, padding=1)\n",
    "        # size: 32 x 16 x 16\n",
    "        self.set2_dec4 = nn.ConvTranspose2d(in_channels=2*latent_dim2,out_channels=3, kernel_size=4, stride=2, padding=1)\n",
    "        # size: 3 x 32 x 32\n",
    "        \n",
    "        self.SVHNc1 = nn.Conv2d(latent_dim2, latent_dim2, 4, 1, 0)\n",
    "        # size: 16 x 1 x 1\n",
    "        self.SVHNc2 = nn.Conv2d(latent_dim2, latent_dim2, 4, 1, 0)\n",
    "        # size: 16 x 1 x 1\n",
    "        self.register_parameter(name='g11', param = nn.Parameter(torch.randn(latent_dim1,latent_dim2)))\n",
    "        self.register_parameter(name='g22', param = nn.Parameter(torch.randn(latent_dim1,latent_dim2)))\n",
    "        self.g12= torch.zeros(latent_dim1,latent_dim2).to(device)\n",
    "    def weighted_mse_loss(self,weights,reconstruction,data):\n",
    "        loss = torch.sum(weights * ((data - reconstruction) ** 2).T)\n",
    "        return loss\n",
    "    def forward(self,x1,x2):\n",
    "        data1    = x1 #MNIST\n",
    "        data2    = x2 #SVHN\n",
    "        # Modality 1 (MNIST)\n",
    "        x1       = F.relu(self.set1_enc1(x1))\n",
    "        x1       = F.relu(self.set1_enc2(x1))  \n",
    "        x1       = self.set1_enc3(x1).view(-1,2,latent_dim1)  # ->[128,2,32]\n",
    "        mu1      = x1[:,0,:] # ->[128,32]\n",
    "        log_var1 = x1[:,1,:] # ->[128,32]\n",
    "        var1     = -torch.exp(log_var1)           #lambdap_2<0\n",
    "        # Modality 2 (SVHN)\n",
    "        x2 = x2.view(-1,3, 32,32) \n",
    "        x2 = F.relu(self.set2_enc1(x2))\n",
    "        x2 = F.relu(self.set2_enc2(x2))\n",
    "        x2 = F.relu(self.set2_enc3(x2))\n",
    "        # get 'mu' and 'log_var' for SVHN\n",
    "        mu2      = (self.SVHNc1(x2).squeeze(3)).squeeze(2)\n",
    "        log_var2 = (self.SVHNc2(x2).squeeze(3)).squeeze(2)\n",
    "        var2     = -torch.exp(log_var2)       \n",
    "        g22      = -torch.exp(self.g22)     \n",
    "        G1       = torch.cat((self.g11,self.g12),0)\n",
    "        G2       = torch.cat((self.g12,g22),0)\n",
    "        G        = torch.cat((G1,G2),1)\n",
    "        print('mu1',mu1.sum())\n",
    "        z1_prior,z2_prior,z1_posterior,z2_posterior,IS_weights_prior,IS_weights_post,KLD = self.IS_sampler.calc(G,mu1,var1,mu2,var2,self.n_IW_samples)\n",
    "        total_reconstruction_loss = torch.tensor([0]).to(device)\n",
    "        for i in range(self.n_IW_samples):\n",
    "            self.z1_IS_posterior = z1_posterior[i].unsqueeze(0).repeat(self.batch_size,1)\n",
    "            self.z2_IS_posterior = z2_posterior[i].unsqueeze(0).repeat(self.batch_size,1, 1,1)\n",
    "            #print('self.z1_IS_posterior',torch.sum(self.z1_IS_posterior) )\n",
    "            self.z1_IS_posterior = (self.z1_IS_posterior.T*IS_weights_post[:,i]).T\n",
    "            self.z2_IS_posterior = (self.z2_IS_posterior.T*IS_weights_post[:,i]).T\n",
    "            #print('self.z1_IS_posterior',torch.sum(self.z1_IS_posterior) )\n",
    "            # decoding for MNIST\n",
    "            x1 = F.relu(self.set1_dec1(self.z1_IS_posterior))\n",
    "            x1 = self.set1_dec2(x1)\n",
    "            # decoding for SVHN\n",
    "            x2 = F.relu(self.set2_dec0(self.z2_IS_posterior))\n",
    "            x2 = F.relu(self.set2_dec1(x2))\n",
    "            x2 = F.relu(self.set2_dec2(x2))\n",
    "            x2 = F.relu(self.set2_dec3(x2))\n",
    "            self.z2_IS_posterior = self.z2_IS_posterior.squeeze()\n",
    "            if self.use_mse_loss:\n",
    "                reconstruction1 = self.set1_dec3(x1)\n",
    "                reconstruction2 = (self.set2_dec4(x2)).view(-1,3072)\n",
    "                MSE1 = self.weighted_mse_loss(IS_weights_post[:,i],reconstruction1, data1)\n",
    "                MSE2 = self.weighted_mse_loss(IS_weights_post[:,i],reconstruction2, data2)\n",
    "            else:\n",
    "                reconstruction1 = torch.sigmoid(self.set1_dec3(x1))\n",
    "                reconstruction2 = torch.sigmoid((self.set2_dec4(x2)).view(-1,3072))\n",
    "                bce_loss = nn.BCELoss(reduction='sum')\n",
    "                MSE1 = bce_loss(reconstruction1, data1)\n",
    "                MSE2 = bce_loss(reconstruction2, data2)\n",
    "            total_reconstruction_loss = total_reconstruction_loss+MSE1+MSE2+KLD\n",
    "\n",
    "        return self.z1_IS_posterior,self.z2_IS_posterior,reconstruction1,reconstruction2,mu1,var1,mu2,var2,total_reconstruction_loss, MSE1, MSE2, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "proprietary-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state = torch.load(PATH)\n",
    "model = VAE(latent_dim1, latent_dim2, batch_size,use_mse_loss=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "#model.load_state_dict(state['state_dict'])\n",
    "#optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "# for name, para in model.named_parameters():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "featured-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,joint_dataloader,epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_mse1 = 0.0\n",
    "    running_mse2 = 0.0\n",
    "    running_kld  = 0.0\n",
    "    running_loss = 0.0\n",
    "    for i,joint_data in enumerate(joint_dataloader):\n",
    "        data1    = joint_data[0]\n",
    "        data1    = data1.float()\n",
    "        data2   = joint_data[1]\n",
    "        data2   = data2.float()\n",
    "        data1    = data1.to(device)\n",
    "        data2   = data2.to(device)\n",
    "        data1    = data1.view(data1.size(0), -1)\n",
    "        data2   = data2.view(data2.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        z1_posterior,z2_posterior,reconstruction1,reconstruction2,mu1,var1,mu2,var2,loss, MSE1, MSE2, KLD       = model(data1,data2) \n",
    "        running_mse1 += MSE1.item()\n",
    "        running_mse2 += MSE2.item()\n",
    "        running_kld  += KLD.item()\n",
    "        running_loss += loss.item()          #.item converts tensor with one element to number\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            loss.backward()                      #.backward\n",
    "        optimizer.step()                     #.step one learning step\n",
    "    train_loss = running_loss/(len(joint_dataloader.dataset))\n",
    "    mse1_loss = running_mse1 / (len(joint_dataloader.dataset))\n",
    "    mse2_loss = running_mse2 / (len(joint_dataloader.dataset))\n",
    "    kld_loss = running_kld / (len(joint_dataloader.dataset))\n",
    "#     for name, param in model.named_parameters():\n",
    "#         writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
    "    writer.add_scalar(\"training/loss\", train_loss, epoch)\n",
    "    writer.add_scalar(\"training/MSE1\", mse1_loss, epoch)\n",
    "    writer.add_scalar(\"training/MSE2\", mse2_loss, epoch)\n",
    "    writer.add_scalar(\"training/KLD\", kld_loss, epoch)    \n",
    "    return train_loss\n",
    "    \n",
    "def test(model,joint_dataloader,epoch):\n",
    "    latent_repMNIST= []\n",
    "    latent_repSVHN= []\n",
    "    label_mnist= []\n",
    "    label_svhn= []\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_mse1 = 0.0\n",
    "    running_mse2 = 0.0\n",
    "    running_kld  = 0.0\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i,joint_data in enumerate(joint_dataloader):\n",
    "            data1   = joint_data[0]\n",
    "            data1   = data1.float()\n",
    "\n",
    "            data2  =joint_data[1]\n",
    "            data2 = data2.float()\n",
    "\n",
    "            label1  =joint_data[2]\n",
    "            label2  =joint_data[3]\n",
    "            \n",
    "            data1 = data1.to(device)\n",
    "            data2 = data2.to(device)\n",
    "            data1 = data1.view(data1.size(0), -1)\n",
    "            data2 = data2.view(data2.size(0), -1)\n",
    "            \n",
    "            z1_posterior,z2_posterior,reconstruction1,reconstruction2,mu1,var1,mu2,var2,loss, MSE1, MSE2, KLD = model(data1,data2)  \n",
    "            running_loss += loss.item()\n",
    "            running_mse1 += MSE1.item()\n",
    "            running_mse2 += MSE2.item()\n",
    "            running_kld  += KLD.item()    \n",
    "            \n",
    "            latent_repMNIST.append(z1_posterior)\n",
    "            latent_repSVHN.append(z2_posterior)\n",
    "            label_mnist.append(label1)\n",
    "            label_svhn.append(label2)\n",
    "\n",
    "            #save the last batch input and output of every epoch\n",
    "            if i == int(len(joint_dataloader.dataset)/joint_dataloader.batch_size) - 1:\n",
    "                num_rows = 8\n",
    "                both = torch.cat((data1.view(batch_size, 1, 28, 28)[:8], \n",
    "                                  reconstruction1.view(batch_size, 1, 28, 28)[:8]))\n",
    "                bothp = torch.cat((data2.view(batch_size, 3, 32, 32)[:8], \n",
    "                                  reconstruction2.view(batch_size, 3, 32, 32)[:8]))\n",
    "                save_image(both.cpu(), os.path.join(RECONSTRUCTION_PATH, f\"1_outputMNIST_{epoch}.png\"), nrow=num_rows)\n",
    "                save_image(bothp.cpu(), os.path.join(RECONSTRUCTION_PATH, f\"1_outputSVHN_{epoch}.png\"), nrow=num_rows)\n",
    "    test_loss = running_loss/(len(joint_dataloader.dataset))\n",
    "    mse1_loss = running_mse1 / (len(joint_dataloader.dataset))\n",
    "    mse2_loss = running_mse2 / (len(joint_dataloader.dataset))\n",
    "    kld_loss = running_kld / (len(joint_dataloader.dataset))\n",
    "    writer.add_scalar(\"validation/loss\", test_loss, epoch)\n",
    "    writer.add_scalar(\"validation/MSE1\", mse1_loss, epoch)\n",
    "    writer.add_scalar(\"validation/MSE2\", mse2_loss, epoch)\n",
    "    writer.add_scalar(\"validation/KLD\", kld_loss, epoch)\n",
    "    latent_repMNIST = torch.vstack(latent_repMNIST).cpu().numpy()\n",
    "    latent_repSVHN  = torch.vstack(latent_repSVHN).cpu().numpy()\n",
    "    label_mnist     = torch.hstack(label_mnist).cpu().numpy()\n",
    "    label_svhn      = torch.hstack(label_svhn).cpu().numpy()\n",
    "    return test_loss,latent_repMNIST,latent_repSVHN,label_mnist,label_svhn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "approved-leeds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 5\n",
      "mu1 tensor(-1.5125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "mu1 tensor(0., device='cuda:0')\n",
      "mu2 tensor(0., device='cuda:0')\n",
      "var1 tensor(0., device='cuda:0')\n",
      "var2 tensor(0., device='cuda:0')\n",
      "g11 tensor(0.1593, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "g22 tensor(-8.2367, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "g12 tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "g21 tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "mu1 tensor(-1.5125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "mu2 tensor(-1.8217, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "var1 tensor(-131.2579, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "var2 tensor(-142.2895, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "g11 tensor(0.1593, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "g22 tensor(-8.2367, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "g12 tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "g21 tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "t_x_prior tensor([[2.9880e-17, 1.2309e-26, 9.6696e-26,  ..., 5.8207e-39, 1.8049e-16,\n",
      "         1.2738e-08],\n",
      "        [2.9880e-17, 1.2309e-26, 9.6696e-26,  ..., 5.8207e-39, 1.8049e-16,\n",
      "         1.2738e-08],\n",
      "        [2.9880e-17, 1.2309e-26, 9.6696e-26,  ..., 5.8207e-39, 1.8049e-16,\n",
      "         1.2738e-08],\n",
      "        ...,\n",
      "        [2.9880e-17, 1.2309e-26, 9.6696e-26,  ..., 5.8207e-39, 1.8049e-16,\n",
      "         1.2738e-08],\n",
      "        [2.9880e-17, 1.2309e-26, 9.6696e-26,  ..., 5.8207e-39, 1.8049e-16,\n",
      "         1.2738e-08],\n",
      "        [2.9880e-17, 1.2309e-26, 9.6696e-26,  ..., 5.8207e-39, 1.8049e-16,\n",
      "         1.2738e-08]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "t_x_post tensor([[1.4491e-34, 4.5873e-23, 0.0000e+00,  ..., 0.0000e+00, 6.7056e-39,\n",
      "         0.0000e+00],\n",
      "        [1.4432e-34, 4.9306e-23, 0.0000e+00,  ..., 0.0000e+00, 4.4359e-39,\n",
      "         0.0000e+00],\n",
      "        [1.3229e-34, 4.3149e-23, 0.0000e+00,  ..., 0.0000e+00, 6.7270e-39,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [1.2964e-34, 4.4697e-23, 0.0000e+00,  ..., 0.0000e+00, 6.3192e-39,\n",
      "         0.0000e+00],\n",
      "        [1.3623e-34, 4.1492e-23, 0.0000e+00,  ..., 0.0000e+00, 5.5437e-39,\n",
      "         0.0000e+00],\n",
      "        [1.5005e-34, 4.8492e-23, 0.0000e+00,  ..., 0.0000e+00, 9.0984e-39,\n",
      "         0.0000e+00]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "3 tensor(64., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [64, 20]], which is output 0 of ExpBackward, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-aa326a2bdc71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} of {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjoint_dataset_train_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtest_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_repMNIST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_repSVHN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_mnist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_svhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjoint_dataset_test_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-9ccade26cb34>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, joint_dataloader, epoch)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m#.item converts tensor with one element to number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                      \u001b[0;31m#.backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                     \u001b[0;31m#.step one learning step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoint_dataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/achint-env2/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/achint-env2/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [64, 20]], which is output 0 of ExpBackward, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 5\n",
    "writer=SummaryWriter(SUMMARY_WRITER_PATH)\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss = train(model,joint_dataset_train_loader,epoch)\n",
    "    test_epoch_loss,latent_repMNIST,latent_repSVHN,label_mnist,label_svhn = test(model,joint_dataset_test_loader,epoch)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    test_loss.append(test_epoch_loss)     \n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "    print(f\"Test Loss: {test_epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = torch.randn(64)\n",
    "# data = torch.randn(64,784)\n",
    "# reconstruction = data\n",
    "# loss = torch.sum( weights*((data - reconstruction) ** 2).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-brick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
